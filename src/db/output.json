[
    {
        "__EMPTY": 1,
        "A": "grpno",
        "B": "title",
        "C": "member1",
        "D": "member2",
        "E": "member3",
        "F": "member4",
        "G": "guide",
        "H": "coguide",
        "I": "description",
        "J": "github",
        "K": "demo",
        "L": "domain",
        "M": "Research Paper Doc",
        "N": "Fundings Received",
        "O": "member1 photo",
        "P": "member2 photo",
        "Q": "member3 photo",
        "R": "member4 photo",
        "S": "guide photo",
        "T": "coguide photo"
    },
    {
        "__EMPTY": 2,
        "A": 1,
        "B": "Detecting cyberbullying using Deep learning",
        "C": "Prasad Jawale",
        "D": "Anushka Kulkarni",
        "E": "Subrato Tapaswi",
        "F": "Lakshman Bhojwani",
        "G": "Dr. Vijayalaxmi",
        "H": "Mamata C",
        "I": "The project, titled \"Detecting Cyberbullying using Deep Learning,\" aims to investigate cyber aggression on Twitter, focusing on identifying derogatory tweets based on gender, race, or sexual orientation. It seeks to develop an automated system capable of accurately analyzing text-based content across online platforms to detect instances of cyberbullying.\n\nLeveraging a dataset of approximately 110,000 instances, the study explores various detection methods, including non-deep learning approaches such as SVM, L2 regularization, and random forest, as well as deep learning techniques utilizing BERT. Additionally, an ensemble learning approach combining BERT and LSTM is planned.\n\nThe classification system categorizes tweets into six major categories: gender, age, religion, not cyberbullying, and ethnicity. To evaluate the effectiveness of these methods, a test dataset of 20,000 tweets will be employed, facilitating a comparative analysis to determine which model best identifies and classifies cyberbullying tweets accurately.",
        "J": "https://github.com/Tydos/Cyberbullying-Detection/tree/main",
        "K": null,
        "L": "Deep Learning",
        "M": null,
        "N": null,
        "O": "https://media.licdn.com/dms/image/C4D03AQEo4bsvzTnLiQ/profile-displayphoto-shrink_400_400/0/1662101524731?e=1716422400&v=beta&t=nVWBD-j6jzxRMqoi68-IqvyTYOUY362evosUvlefRiU",
        "P": "https://media.licdn.com/dms/image/D4D03AQFpnIgP_yWpMQ/profile-displayphoto-shrink_400_400/0/1661488412068?e=1716422400&v=beta&t=Xo523AtSgqlrbnaM42BJRn-VOUSILAdSgaUp4kIe6kg",
        "Q": "https://media.licdn.com/dms/image/D4D03AQE-FgVY2UxL_w/profile-displayphoto-shrink_800_800/0/1711113775780?e=1716422400&v=beta&t=bkxJvDbxpPsEa1Q0Ceetw5YLWYsMm4lHcxBN_D1hVN4",
        "R": "Lakshman Bhojwani",
        "S": null,
        "T": "Mamata C"
    },
    {
        "__EMPTY": 3,
        "A": 2,
        "B": "SecurGAN",
        "C": "Arunim Chakraborty",
        "D": "Satyam Dubey",
        "E": "Prathmesh Pawar",
        "F": "Yash Sarang",
        "G": "Dr. Anjali Yeole",
        "H": "Himanshi G",
        "I": "The project, titled \"SecurGAN: AI-Powered Facial Inpainting for Enhanced Law Enforcement and Security,\" aims to develop a system utilizing AI-powered facial inpainting techniques with Generative Adversarial Neural Networks (GANs). This system reconstructs the facial features of an unknown person who has covered their face, generating an accurate representation based on visible features and contextual information in the image. Its goal is to provide law enforcement agencies with a tool that assists in identifying individuals involved in criminal activities or other security-related incidents where their faces are obscured, enhancing the capabilities of law enforcement personnel in gathering information and solving cases effectively through advanced machine learning algorithms.",
        "J": "https://github.com/prathmeshppawar/Major-Project",
        "K": null,
        "L": "Computer Vision",
        "M": null,
        "N": null,
        "O": "Arunim Chakraborty",
        "P": "Satyam Dubey",
        "Q": "https://media.licdn.com/dms/image/C4D03AQHJi3HY2BphPw/profile-displayphoto-shrink_400_400/0/1662209363149?e=1716422400&v=beta&t=tVTvuQCRVcmv1kFTLjDb4iR3Vyb8eDMyJb1wvesfDio",
        "R": "Yash Sarang",
        "S": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
        "T": "Himanshi G"
    },
    {
        "__EMPTY": 4,
        "A": 3,
        "B": "Location Predictor",
        "C": "Akanksha Singh",
        "D": "Ashish Gupta",
        "E": "Abhijay Sharangdhar",
        "F": "Hrishikesh Kudale",
        "G": "Sangeeta Oswal",
        "H": "Bhavana C",
        "I": "In the vibrant city of Mumbai, where the aroma of freshly brewed coffee fills the air on every street corner, finding the perfect location for a new coffee shop is both a challenge and an opportunity. Businesses like AbCoffee are constantly seeking ways to expand their footprint and capture new markets, but the process of selecting an ideal location can be daunting. Traditional methods of site selection often rely on intuition or anecdotal evidence, leading to suboptimal decisions and potentially costly mistakes.\n\nTo address this challenge, our project undertakes a data-driven approach to spatial analysis, leveraging the power of data science techniques to identify optimal locations for coffee shop expansion in Mumbai. By harnessing comprehensive datasets encompassing cafe locations, real estate pricing, and transportation accessibility, we aim to provide businesses with actionable insights to support strategic decision-making.\n\nThe heart of our approach lies in clustering analysis, specifically employing the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm. This algorithm allows us to identify clusters of cafes based on geographic proximity, enabling us to understand patterns of cafe distribution across the city. By analyzing the characteristics of these clusters, such as cafe density, variety, and proximity to transportation hubs, we gain valuable insights into the underlying factors driving the success of existing coffee outlets.\n\nMoreover, our analysis extends beyond cafe locations to encompass broader market dynamics, including real estate pricing and transportation accessibility. By integrating data on property prices per square foot across different localities in Mumbai and assessing the proximity of cafe clusters to train stations and other transportation hubs, we gain a comprehensive understanding of the market landscape.\n\nOne of the key advantages of our approach is its scalability and adaptability. While our initial focus is on coffee shop expansion in Mumbai, the methodology and techniques employed can be applied to other cities and regions with minimal modifications. This scalability not only enhances the generalizability of our findings but also allows businesses to replicate our approach in diverse market environments.\n\nThe recommendations generated by our analysis provide businesses like AbCoffee with actionable insights to support their expansion efforts. By identifying potential locations with high business potential and minimal competition, businesses can minimize risks and maximize their chances of success in a competitive market landscape.\n\nIn conclusion, our project represents a powerful application of data science techniques to support strategic decision-making in coffee shop expansion. By harnessing the power of data, we empower businesses to make informed decisions, seize opportunities for growth, and thrive in dynamic market environments.",
        "J": "https://github.com/akanksha2828/Major-Project/blob/master/abcoffee_prediction.ipynb",
        "K": null,
        "L": null,
        "M": null,
        "N": null,
        "O": "Akanksha Singh",
        "P": "Ashish Gupta",
        "Q": "Abhijay Sharangdhar",
        "R": "Hrishikesh Kudale",
        "S": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
        "T": "Bhavana C"
    },
    {
        "__EMPTY": 5,
        "A": 4,
        "B": "Language Text Summarisation",
        "C": "Siddhant Dongre",
        "D": "Shubham Hadawle",
        "E": "Pranav Kotkar",
        "F": "Om Bhatia",
        "G": "Amit Singh",
        "H": "Akansha P",
        "I": null,
        "J": null,
        "K": null,
        "L": "NLP",
        "M": null,
        "N": null,
        "O": "Siddhant Dongre",
        "P": "Shubham Hadawle",
        "Q": "Pranav Kotkar",
        "R": "Om Bhatia",
        "S": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
        "T": "Akansha P"
    },
    {
        "__EMPTY": 6,
        "A": 5,
        "B": "AI Based smart meter",
        "C": "Sarthak Bansod",
        "D": "Sheryl Bellary",
        "E": "Sheetal Dixit",
        "F": "Soham Jadiye",
        "G": "Ajinkya W",
        "H": "Kusum K",
        "I": null,
        "J": null,
        "K": null,
        "L": null,
        "M": null,
        "N": null,
        "O": "Sarthak Bansod",
        "P": "Sheryl Bellary",
        "Q": "Sheetal Dixit",
        "R": "Soham Jadiye",
        "S": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
        "T": "Kusum K"
    },
    {
        "__EMPTY": 7,
        "A": 6,
        "B": "Visual Speech Recognition using AI",
        "C": "Akshat Tiwari",
        "D": "Arya Kurup",
        "E": "Rupesh Dhirwani",
        "F": "Tejas Patne",
        "G": "Dr. Vijayalaxmi",
        "H": "Mamata C",
        "I": "Visual speech recognition using deep learning involves the utilization of neural network architectures to predict speech content solely based on visual cues extracted from videos of speakers. This technology holds significant potential for various applications, including improving speech recognition accuracy in noisy environments, aiding individuals with hearing impairments, enhancing human-computer interaction in multimedia systems, and facilitating automatic transcription of videos. The first step involves preprocessing the video data to extract relevant visual features. This typically involves techniques such as face detection and tracking, lip region segmentation, and feature extraction. Common features include lip movements, facial expressions, and head gestures. LipNet is a deep learning architecture specifically designed for lip reading. It combines convolutional neural networks (CNNs) for feature extraction from lip images with recurrent neural networks (RNNs) such as Long Short-Term Memory (LSTM) networks for sequence modeling and prediction.STCNNs are specialized architectures designed to capture both spatial and temporal information from video data. They typically consist of 3D convolutional layers followed by fully connected layers for classification or prediction tasks. Bi-LSTMs are recurrent neural networks that process input sequences in both forward and backward directions, enabling them to capture temporal dependencies effectively. They are often used for sequence modeling tasks such as speech recognition and natural languageprocessing. Once the architecture is selected, the model is trained using labeled video data, where the input consists of visual features extracted from video frames, and the output is the corresponding speech content. The training process involves optimizing the model parameters to minimize prediction errors using techniques like stochastic gradient descent (SGD) or adaptive optimization algorithms like Adam. After training, the model is evaluated on a separate test set to assess its performance. Common evaluation metrics include accuracy, precision, recall, and F1 score. Additionally, qualitative assessment through visual inspection of predictions can provide insights into the model&#39;s strengths and weaknesses. Once the model is trained and evaluated satisfactorily, it can be deployed for real-world applications. These applications may include real-time speech recognition in videos, automatic transcription of spoken content, enhancing accessibility for individuals with hearing impairments, and integrating with multimedia systems for interactive experiences. Overall, visual speech recognition using deep learning holds promise for advancing the state-of-the-art in speech processing and multimedia technology, with potential benefits across various domains.\n",
        "J": "https://github.com/TejasPatne/visual-speech-recognition/tree/main",
        "K": null,
        "L": "Computer Vision",
        "M": null,
        "N": null,
        "O": "Akshat Tiwari",
        "P": "Arya Kurup",
        "Q": "Rupesh Dhirwani",
        "R": "https://media.licdn.com/dms/image/D4D03AQGJTp4t23B0kQ/profile-displayphoto-shrink_200_200/0/1711108637180?e=2147483647&v=beta&t=2ugzieM9eEfqdWJ8BkKa8yJy2_duw3vLHHuLBqYPsvE",
        "S": null,
        "T": "Mamata C"
    },
    {
        "__EMPTY": 8,
        "A": 7,
        "B": "Predicting malnutition of baby from pregnant mother",
        "C": "Vemburaj Konar",
        "D": "Mayur Pimpude",
        "E": "Heramb Pawar",
        "F": "Deepak Prasad",
        "G": "Dr. Anjali Yeole",
        "H": "Himanshi G",
        "I": "The objective is to leverage machine learning and Deep Learning to accurately assess the malnutrition vulnerability of infants using demographic and socio-economic attributes from the census data.\nThe creation of a user-friendly dashboard will allow healthcare practitioners and policymakers to efficiently interpret and explore the prediction outcomes, facilitating targeted interventions and evidence-based decision-making to address malnutrition and its associated challenges among newborn\n",
        "J": "https://github.com/MayurPimpude/BE-Project",
        "K": null,
        "L": "Deep Learning",
        "M": null,
        "N": null,
        "O": "https://media.licdn.com/dms/image/D4D03AQHpbb7DZ0teyw/profile-displayphoto-shrink_400_400/0/1693139740090?e=1716422400&v=beta&t=Vz5dRLjSSAOSIoLINJd5Ei1C4cpcAIT3pQtD0ZYmb98",
        "P": "https://media.licdn.com/dms/image/D5603AQHkUvL0yIjeMQ/profile-displayphoto-shrink_400_400/0/1690610996503?e=1716422400&v=beta&t=_qri5lB_rbdxWKkhmBFY15uJfaPdRfLlj643vUeddZw",
        "Q": "https://media.licdn.com/dms/image/D4D35AQFxzBDdeex6iA/profile-framedphoto-shrink_400_400/0/1690345194603?e=1711717200&v=beta&t=gwmnfc5F8WjywvpcZOYAzqezMVq8gtAn2CN-V3G4Pgs",
        "R": "https://media.licdn.com/dms/image/D4D35AQGDIzw635ii5g/profile-framedphoto-shrink_400_400/0/1673147093442?e=1711717200&v=beta&t=df1K4dVT1OWvIKDKSSR15WTwnTmjHUsPyK7s_nuga48",
        "S": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
        "T": "Himanshi G"
    },
    {
        "__EMPTY": 9,
        "A": 8,
        "B": "PICTURA-Bring imagination to life",
        "C": "Tanvi Kate",
        "D": "Yash pandey",
        "E": "Gargi Khachane",
        "F": "Saransh Badlani",
        "G": "Sangeeta Oswal",
        "H": "Bhavana C",
        "I": null,
        "J": null,
        "K": null,
        "L": null,
        "M": null,
        "N": null,
        "O": "Tanvi Kate",
        "P": "https://media.licdn.com/dms/image/D4D03AQGIQZL0W44uOw/profile-displayphoto-shrink_400_400/0/1702146568355?e=1716422400&v=beta&t=m7JRdehXFqRvAzO1S2XmA8yKCiQd-0DNSLNrzsMJdtQ",
        "Q": "Gargi Khachane",
        "R": "Saransh Badlani",
        "S": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
        "T": "Bhavana C"
    },
    {
        "__EMPTY": 10,
        "A": 9,
        "B": "Health Sync-AI Health news App",
        "C": "Shruti Devlekar",
        "D": "Om Gaydhane",
        "E": "Janhavi Khanvilkar",
        "F": "Kshitij Shidore",
        "G": "Amit Singh",
        "H": "Akansha P",
        "I": null,
        "J": null,
        "K": null,
        "L": null,
        "M": null,
        "N": null,
        "O": "Shruti Devlekar",
        "P": "Om Gaydhane",
        "Q": "Janhavi Khanvilkar",
        "R": "Kshitij Shidore",
        "S": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
        "T": "Akansha P"
    },
    {
        "__EMPTY": 11,
        "A": 10,
        "B": "Pharmaceutical Supply Chain Management",
        "C": "Abhishek Thorat",
        "D": "Arnav Singhal",
        "E": "Manvi Gour",
        "F": "Jayesh Agrawal",
        "G": "Ajinkya W",
        "H": "Kusum K",
        "I": "Supply Chain Management System for Pharmacetiucal companies",
        "J": null,
        "K": null,
        "L": "SupplyÂ Chain",
        "M": null,
        "N": null,
        "O": "Abhishek Thorat",
        "P": "Arnav Singhal",
        "Q": "Manvi Gour",
        "R": "Jayesh Agrawal",
        "S": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
        "T": "Kusum K"
    },
    {
        "__EMPTY": 12,
        "A": 11,
        "B": "Generating 3D models from 2D images",
        "C": "Sahil Parab",
        "D": "Akshiti K.",
        "E": "Surabhi Tambe",
        "F": null,
        "G": "Dr. Vijayalaxmi",
        "H": "Mamata C",
        "I": null,
        "J": null,
        "K": null,
        "L": "Deep Learning",
        "M": null,
        "N": null,
        "O": "Sahil Parab",
        "P": "Akshiti K.",
        "Q": "Surabhi Tambe",
        "R": null,
        "S": null,
        "T": "Mamata C"
    },
    {
        "__EMPTY": 13,
        "A": 12,
        "B": "Poshan Sankalp",
        "C": "Surya Ganiga",
        "D": "Nimisha Jain",
        "E": "Rohan Singh",
        "F": null,
        "G": "Dr. Anjali Yeole",
        "H": "Himanshi G",
        "I": null,
        "J": "https://github.com/satts27/MajorProject",
        "K": null,
        "L": "Predictive maintenance",
        "M": null,
        "N": null,
        "O": "Surya Ganiga",
        "P": "Nimisha Jain",
        "Q": "https://media.licdn.com/dms/image/C4D03AQGhdMNK7z3hzw/profile-displayphoto-shrink_200_200/0/1663418927746?e=2147483647&v=beta&t=gnroc__ub3_LuLAVYP944-LL9b8FRyRbEQ2MjZtOrBo",
        "R": null,
        "S": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
        "T": "Himanshi G"
    },
    {
        "__EMPTY": 14,
        "A": 13,
        "B": "Vahan Suraksha Netra",
        "C": "Naresh Shewkani",
        "D": "Himanshu Sharma",
        "E": "Avanish Srivastava",
        "F": "Shambhu Patil",
        "G": "Sangeeta Oswal",
        "H": "Bhavana C",
        "I": null,
        "J": null,
        "K": null,
        "L": null,
        "M": null,
        "N": null,
        "O": "Naresh Shewkani",
        "P": "Himanshu Sharma",
        "Q": "Avanish Srivastava",
        "R": "Shambhu Patil",
        "S": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
        "T": "Bhavana C"
    },
    {
        "__EMPTY": 15,
        "A": 14,
        "B": "AI Assistant for youtube & NPTEL courses",
        "C": "Nikita Jethani",
        "D": "Madhusudana Naidu",
        "E": "Manav Pahilwani",
        "F": "Shreya Singh",
        "G": "Ajinkya W",
        "H": "Kusum K",
        "I": null,
        "J": null,
        "K": null,
        "L": null,
        "M": null,
        "N": null,
        "O": "Nikita Jethani",
        "P": "Madhusudana Naidu",
        "Q": "Manav Pahilwani",
        "R": "Shreya Singh",
        "S": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
        "T": "Kusum K"
    },
    {
        "__EMPTY": 16,
        "A": 15,
        "B": "Predictive maintenance of servers",
        "C": "Harshita Anala",
        "D": "Mahindra Chetwani",
        "E": "Manas Lalwani",
        "F": "Parth Suryavanshi",
        "G": "Dr. Anjali Yeole",
        "H": "Himanshi G",
        "I": "Our proposal involves creating a web application that utilises machine sensor data to forecast the likelihood of machine downtime based on the historical data of its servers components . This is going to be carried out by\n1. Carry out data cleaning on the data set that includes records of various parameters gathered by the server&#39;s sensors, and look for correlations to find patterns related to the server&#39;s downtime.\n2. Determine and train the best machine learning model that can predict system failure well in advance using the live data supplied to the corresponding model after analysing the data set and determining the correlation.\n3. In terms of operations, the model will be highly helpful to the person operating the machine, as well as to their individual managers and other stakeholders. The project is expected to yield highly efficient results while also saving a significant amount of time. Profit and productivity as a whole have increased as a result.",
        "J": null,
        "K": null,
        "L": "Predictive maintenance",
        "M": "https://docs.google.com/document/d/12lpMdo29V86HU1lmmGi7EkL6hY55gu-xRR21Spa_JFE/edit?usp=sharing",
        "N": null,
        "O": "Harshita Anala",
        "P": "Mahindra Chetwani",
        "Q": "Manas Lalwani",
        "R": "Parth Suryavanshi",
        "S": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
        "T": "Himanshi G"
    },
    {
        "__EMPTY": 17,
        "A": 16,
        "B": "Demysification of neural network through explainable AI",
        "C": "Priyanshu Singh",
        "D": "Sneha Kadambala",
        "E": "Shreyas Satre",
        "F": "Atharva khangar",
        "G": "Sangeeta Oswal",
        "H": "Bhavana C",
        "I": "Project Title: Demystification of Neural Networks through Explainable AI\n\nIntroduction:\nIn recent years, neural networks have demonstrated remarkable capabilities in various fields, ranging from image recognition to natural language processing. However, the complexity and \"black-box\" nature of neural networks often pose challenges in understanding their decision-making processes, hindering their widespread adoption in critical applications. To address this challenge, our project aims to demystify neural networks using Explainable Artificial Intelligence (XAI) techniques.\n\nProject Description:\n\nOur project focuses on creating a transparent understanding of neural networks by leveraging a combination of techniques, including autoencoder architectures, Temporal Convolutional Networks (TCN) for time-series data analysis, SHAP (SHapley Additive exPlanations) for model interpretation, and Natural Language Processing (NLP) for intuitive explanation generation.\n\n1. Autoencoder Setup with TCN:\n\nWe begin by constructing an autoencoder architecture tailored for the specific task of analyzing time-series data with 51 feature attributes. Autoencoders are neural networks trained to reconstruct input data, thus learning a compressed representation of the input. We integrate Temporal Convolutional Networks (TCN) within the autoencoder setup to effectively capture temporal dependencies in the time-series data. TCNs are renowned for their ability to model long-range dependencies efficiently, making them suitable for processing sequential data.\n\n2. SHAP Analysis:\n\nOnce the autoencoder with TCN is trained on the dataset, we employ (SHapley Additive exPlanations) SHAP values to understand the importance of each feature attribute in the model&#39;s decision-making process. SHAP provides a coherent explanation of individual predictions by quantifying the impact of each feature on the model&#39;s output. By visualizing SHAP values, users gain insights into how different features influence the neural network&#39;s decisions, enhancing transparency and interpretability.\n\n3. NLP-Based Explanation Generation:\n\nTo further enhance the interpretability of the neural network&#39;s decisions, we leverage Natural Language Processing (NLP) techniques to generate human-readable explanations. By analyzing the learned representations and SHAP values, we extract key insights and transform them into intuitive explanations in natural language. These explanations provide users with actionable insights into the model&#39;s behavior, enabling informed decision-making.\n\nExpected Outcome:\n\nThrough our project, we aim to achieve the following outcomes:\n\nEnhanced Understanding: Provide users with a clear understanding of how neural networks operate, particularly in the context of time-series data analysis with multiple features.\nTransparency: Offer transparent insights into the decision-making process of the neural network, facilitating trust and confidence in its predictions.\nAccessibility: Make complex neural network models accessible to a wider audience by presenting explanations in a comprehensible and intuitive manner.\nPractical Utility: Enable stakeholders to make informed decisions based on the insights gleaned from the explainable AI techniques employed in the project.",
        "J": null,
        "K": null,
        "L": "Deep Learning",
        "M": null,
        "N": null,
        "O": "https://drive.google.com/file/d/1WW9owQ14Umuqh3wRm760l0aNoWrWzakB/view",
        "P": "https://drive.google.com/file/d/19phxsNNpm-sMqi4hDPYaU_GnTdPqD6c8/view?usp=drive_link",
        "Q": "https://drive.google.com/file/d/1dlxgOS15uQwkucE56dg0Hbv8Dp4hMExF/view?usp=drive_link",
        "R": "https://drive.google.com/file/d/15-iqEpgNd5YqMghaz8Jprh3ktdbg7mcx/view?usp=drive_link",
        "S": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
        "T": "Bhavana C"
    },
    {
        "__EMPTY": 18,
        "A": 17,
        "B": "Aspect Base senitiment Analysis",
        "C": "Omkar Korade",
        "D": "Muhammad Faayez",
        "E": "Harsh Rohra",
        "F": "Govind Tiwari",
        "G": "Amit Singh",
        "H": "Akansha P",
        "I": "An ML model that compares a student answer and a model answer and gives the accuracy of how similar both annswers are. This can be used by teachers and by anyone who wants to automate the task of grading tests with descriptive answers. The user needs to input both the model answer and student answer either by typing them out or uploading their images. If images are uploaded the model will utilise the OCR functionality to extract the text from them and proceed ahead.",
        "J": null,
        "K": null,
        "L": "NLP",
        "M": null,
        "N": null,
        "O": "https://media.licdn.com/dms/image/D4D03AQEIa1lSbjc25w/profile-displayphoto-shrink_800_800/0/1704370334344?e=1716422400&v=beta&t=WIyAszqK6bdqdAO_-MfFTptca3khYGaOLdYylNfXX0A",
        "P": "Muhammad Faayez",
        "Q": "Harsh Rohra",
        "R": "https://media.licdn.com/dms/image/C4D03AQHXejxrYN3J_g/profile-displayphoto-shrink_400_400/0/1661512805935?e=1716422400&v=beta&t=o7ZodhYnAczJbVQnBdGNR3YH-t8SdIqyKVwS6Efk_lo",
        "S": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
        "T": "Akansha P"
    }
]